{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "651da19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "54554c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 13:43:37,843 INFO:Crawling: https://maistocadas.mus.br/2021/\n",
      "2023-02-28 13:43:38,330 INFO:Crawling: https://maistocadas.mus.br/2022/\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)s:%(message)s',\n",
    "    level=logging.INFO)\n",
    "\n",
    "class Crawler:\n",
    "\n",
    "    def __init__(self, urls=[]):\n",
    "        self.headers = {\n",
    "          'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/109.0',\n",
    "        }\n",
    "        self.decade = 50\n",
    "        self.visited_urls = []\n",
    "        self.urls_to_visit = urls\n",
    "        self.current_year = 0\n",
    "        self.music_list = []\n",
    "        self.year_list = []\n",
    "        self.top_music_by_year = []\n",
    "        self.add_url_to_visit()\n",
    "\n",
    "    def add_url_to_visit(self):\n",
    "        url = self.urls_to_visit.pop(0)\n",
    "        for i in range(2021,2023):\n",
    "          new_url = url + str(i) + '/'\n",
    "          self.year_list.append(i)\n",
    "          self.urls_to_visit.append(new_url)            \n",
    "        self.current_year = self.year_list.pop(0)\n",
    "    def download_url(self, url):\n",
    "        return requests.get(url, headers=self.headers)\n",
    "\n",
    "    def get_linked_urls(self, url, html):\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for link in soup.find_all('a'):\n",
    "            path = link.get('href')\n",
    "            if path and path.startswith('/'):\n",
    "                path = urljoin(url, path)\n",
    "            yield path\n",
    "            \n",
    "    def parse_list(self, parser, text):\n",
    "        tag = parser.find(class_='lista') \n",
    "        index = 1\n",
    "        for list_item in tag.find_all('li'):\n",
    "          content = list_item.text\n",
    "          content = content.split(' â€“ ')\n",
    "          self.music_list.append(\n",
    "              dict(rank = str(index),\n",
    "                   name = content[0],\n",
    "                   author = content[1]\n",
    "                  ))\n",
    "          index += 1\n",
    "          \n",
    "    def assembly_and_release(self):\n",
    "        top_music = {\n",
    "            'year' : self.current_year,\n",
    "            'music_list' : self.music_list\n",
    "        }\n",
    "        prev_year = self.current_year\n",
    "        if len(self.year_list) > 0:\n",
    "          self.current_year = self.year_list.pop(0)\n",
    "        self.top_music_by_year.append(top_music)\n",
    "        self.music_list = []\n",
    "        if prev_year % 10 == 0:\n",
    "          filename = 'out' +'/' + str(self.decade) + '.json'\n",
    "          self.dump(filename)\n",
    "        if len(self.year_list) == 0:\n",
    "          filename = 'out/20.json'\n",
    "          self.dump(filename)          \n",
    "        \n",
    "    def dump(self, filename):\n",
    "        year = str(self.current_year)\n",
    "        decade = int(year[2:4])\n",
    "        decade = decade - (decade % 10)\n",
    "        self.decade = decade\n",
    "        with open(filename, \"w+\") as outfile:\n",
    "          json.dump(self.top_music_by_year, outfile)\n",
    "        #self.top_music_by_year.clear()\n",
    "\n",
    "    def crawl(self, url):      \n",
    "        html = self.download_url(url)\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        self.parse_list(soup, html.text)\n",
    "        self.assembly_and_release()\n",
    "        \n",
    "    def run(self):\n",
    "        while self.urls_to_visit:\n",
    "            url = self.urls_to_visit.pop(0)\n",
    "            logging.info(f'Crawling: {url}')\n",
    "            try:\n",
    "                self.crawl(url)\n",
    "            except Exception:\n",
    "                logging.exception(f'Failed to crawl: {url}')\n",
    "            finally:\n",
    "                self.visited_urls.append(url)\n",
    "if __name__ == '__main__':\n",
    "    Crawler(urls=['https://maistocadas.mus.br/']).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "247b958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23 % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d30b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
